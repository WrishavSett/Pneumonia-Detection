{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import VGG16\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import Model\nfrom tensorflow.keras.preprocessing import image\nimport numpy as np","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-07T14:13:12.790902Z","iopub.execute_input":"2023-11-07T14:13:12.792143Z","iopub.status.idle":"2023-11-07T14:13:20.768253Z","shell.execute_reply.started":"2023-11-07T14:13:12.792078Z","shell.execute_reply":"2023-11-07T14:13:20.767421Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"# Set the paths to your dataset\ntrain_dir = '/kaggle/input/chest-xray-pneumonia/chest_xray/train'\ntest_dir = '/kaggle/input/chest-xray-pneumonia/chest_xray/test'\nval_dir = '/kaggle/input/chest-xray-pneumonia/chest_xray/val'\n\n# Image dimensions and batch size\nimage_size = (224, 224)\nbatch_size = 32","metadata":{"execution":{"iopub.status.busy":"2023-11-07T14:13:20.770195Z","iopub.execute_input":"2023-11-07T14:13:20.770870Z","iopub.status.idle":"2023-11-07T14:13:20.775883Z","shell.execute_reply.started":"2023-11-07T14:13:20.770835Z","shell.execute_reply":"2023-11-07T14:13:20.774911Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Data augmentation for the training dataset\ntrain_datagen = ImageDataGenerator(\n    rescale=1.0/255,\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    fill_mode='nearest'\n)\n\n# Preprocess and augment the training data\ntrain_generator = train_datagen.flow_from_directory(\n    train_dir,\n    target_size=image_size,\n    batch_size=batch_size,\n    class_mode='binary'\n)","metadata":{"execution":{"iopub.status.busy":"2023-11-07T14:13:20.776960Z","iopub.execute_input":"2023-11-07T14:13:20.777341Z","iopub.status.idle":"2023-11-07T14:13:24.235914Z","shell.execute_reply.started":"2023-11-07T14:13:20.777307Z","shell.execute_reply":"2023-11-07T14:13:24.235198Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Found 5216 images belonging to 2 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Preprocess the test\ntest_datagen = ImageDataGenerator(rescale=1.0/255)\n\ntest_generator = test_datagen.flow_from_directory(\n    test_dir,\n    target_size=image_size,\n    batch_size=batch_size,\n    class_mode='binary'\n)","metadata":{"execution":{"iopub.status.busy":"2023-11-07T14:13:24.237929Z","iopub.execute_input":"2023-11-07T14:13:24.238201Z","iopub.status.idle":"2023-11-07T14:13:24.328706Z","shell.execute_reply.started":"2023-11-07T14:13:24.238177Z","shell.execute_reply":"2023-11-07T14:13:24.327956Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Found 624 images belonging to 2 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Preprocess the validation data\nval_generator = test_datagen.flow_from_directory(\n    val_dir,\n    target_size=image_size,\n    batch_size=batch_size,\n    class_mode='binary'\n)","metadata":{"execution":{"iopub.status.busy":"2023-11-07T14:13:24.330843Z","iopub.execute_input":"2023-11-07T14:13:24.331511Z","iopub.status.idle":"2023-11-07T14:13:24.349419Z","shell.execute_reply.started":"2023-11-07T14:13:24.331482Z","shell.execute_reply":"2023-11-07T14:13:24.348670Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Found 16 images belonging to 2 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"#Pretrained VGG16 + CNN Model\n\nbase_model = VGG16(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\nfor layer in base_model.layers:\n    layer.trainable = False\n\nx = layers.Flatten()(base_model.output)\nx = layers.Dense(512, activation='relu')(x)\nx = layers.Dropout(0.5)(x)\nx = layers.Dense(1, activation='sigmoid')(x)\n\nmodel = Model(base_model.input, x)","metadata":{"execution":{"iopub.status.busy":"2023-11-07T14:13:24.350321Z","iopub.execute_input":"2023-11-07T14:13:24.350559Z","iopub.status.idle":"2023-11-07T14:13:31.342934Z","shell.execute_reply.started":"2023-11-07T14:13:24.350537Z","shell.execute_reply":"2023-11-07T14:13:31.341370Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n58889256/58889256 [==============================] - 3s 0us/step\n","output_type":"stream"}]},{"cell_type":"code","source":"# Compile the model\nmodel.compile(optimizer=tf.keras.optimizers.Adam(lr=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n\n# Train the model\nhistory = model.fit(train_generator, epochs=5, validation_data=val_generator)","metadata":{"execution":{"iopub.status.busy":"2023-11-07T14:13:48.119783Z","iopub.execute_input":"2023-11-07T14:13:48.120185Z","iopub.status.idle":"2023-11-07T14:22:32.203311Z","shell.execute_reply.started":"2023-11-07T14:13:48.120151Z","shell.execute_reply":"2023-11-07T14:22:32.202287Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Epoch 1/5\n163/163 [==============================] - 140s 803ms/step - loss: 0.5241 - accuracy: 0.8484 - val_loss: 0.4778 - val_accuracy: 0.7500\nEpoch 2/5\n163/163 [==============================] - 96s 587ms/step - loss: 0.2337 - accuracy: 0.9020 - val_loss: 0.7150 - val_accuracy: 0.6875\nEpoch 3/5\n163/163 [==============================] - 96s 587ms/step - loss: 0.2090 - accuracy: 0.9137 - val_loss: 0.5912 - val_accuracy: 0.6875\nEpoch 4/5\n163/163 [==============================] - 96s 586ms/step - loss: 0.1952 - accuracy: 0.9199 - val_loss: 0.4236 - val_accuracy: 0.7500\nEpoch 5/5\n163/163 [==============================] - 96s 590ms/step - loss: 0.1931 - accuracy: 0.9216 - val_loss: 0.4695 - val_accuracy: 0.6875\n","output_type":"stream"}]},{"cell_type":"code","source":"# Evaluate the model on the test set\ntest_loss, test_accuracy = model.evaluate(test_generator)\nprint(f'Test accuracy: {test_accuracy * 100:.2f}%')","metadata":{"execution":{"iopub.status.busy":"2023-11-07T14:22:43.278567Z","iopub.execute_input":"2023-11-07T14:22:43.278945Z","iopub.status.idle":"2023-11-07T14:22:53.382084Z","shell.execute_reply.started":"2023-11-07T14:22:43.278912Z","shell.execute_reply":"2023-11-07T14:22:53.381263Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"20/20 [==============================] - 10s 485ms/step - loss: 0.2708 - accuracy: 0.9006\nTest accuracy: 90.06%\n","output_type":"stream"}]},{"cell_type":"code","source":"# Save the model\nmodel.save('/kaggle/working/pneumonia_model.h5')","metadata":{"execution":{"iopub.status.busy":"2023-11-07T14:22:57.487657Z","iopub.execute_input":"2023-11-07T14:22:57.488533Z","iopub.status.idle":"2023-11-07T14:22:57.915232Z","shell.execute_reply.started":"2023-11-07T14:22:57.488496Z","shell.execute_reply":"2023-11-07T14:22:57.914170Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Load the trained model\nmodel = tf.keras.models.load_model('/kaggle/working/pneumonia_model.h5')\n\n# Load an example image for prediction\nimage_path = '/kaggle/input/chest-xray-pneumonia/chest_xray/val/NORMAL/NORMAL2-IM-1440-0001.jpeg'\nimg = image.load_img(image_path, target_size=(224, 224))\nimg = image.img_to_array(img)\nimg = np.expand_dims(img, axis=0)\n\n# Make prediction\npredictions = model.predict(img)\nprint(predictions)\n# Interpret the prediction\nif predictions[0] > 0.5:\n    print(\"The image is NORMAL.\")\nelse:\n    print(\"The image indicates PNEUMONIA.\")","metadata":{"execution":{"iopub.status.busy":"2023-11-07T14:24:43.177662Z","iopub.execute_input":"2023-11-07T14:24:43.178299Z","iopub.status.idle":"2023-11-07T14:24:44.357754Z","shell.execute_reply.started":"2023-11-07T14:24:43.178266Z","shell.execute_reply":"2023-11-07T14:24:44.356554Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"1/1 [==============================] - 0s 151ms/step\n[[0.]]\nThe image indicates PNEUMONIA.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Load the trained model\nmodel = tf.keras.models.load_model('/kaggle/working/pneumonia_model.h5')\n\n# Load an example image for prediction\nimage_path = '/kaggle/input/chest-xray-pneumonia/chest_xray/val/PNEUMONIA/person1949_bacteria_4880.jpeg'\nimg = image.load_img(image_path, target_size=(224, 224))\nimg = image.img_to_array(img)\nimg = np.expand_dims(img, axis=0)\n\n# Make prediction\npredictions = model.predict(img)\nprint(predictions)\n# Interpret the prediction\nif predictions[0] > 0.5:\n    print(\"The image is NORMAL.\")\nelse:\n    print(\"The image indicates PNEUMONIA.\")","metadata":{"execution":{"iopub.status.busy":"2023-11-07T14:24:44.359649Z","iopub.execute_input":"2023-11-07T14:24:44.360358Z","iopub.status.idle":"2023-11-07T14:24:45.553129Z","shell.execute_reply.started":"2023-11-07T14:24:44.360320Z","shell.execute_reply":"2023-11-07T14:24:45.552137Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"1/1 [==============================] - 0s 148ms/step\n[[0.]]\nThe image indicates PNEUMONIA.\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}